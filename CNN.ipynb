{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68654d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4e6ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'JPEGImages', 'train', 'labels_full.csv', 'Annotations', 'labels.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/feriniqation/cnn-blood-cells-classification\n",
    "os.listdir('/home/lea/Documents/M2/DEA/Tata/CNNBloodCell/dataset-master/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b63b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('/home/lea/Documents/M2/DEA/Tata/CNNBloodCell/dataset-master/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "885ed554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "labels_df = pd.read_csv(PATH.joinpath('labels_full.csv'))\n",
    "labels_df = labels_df.dropna(subset=['Image', 'Category'])\n",
    "labels_df['Image'] = labels_df['Image'].apply(\n",
    "    lambda x: 'BloodImage_0000' + str(x) + '.jpg' \n",
    "    if x < 10 \n",
    "    else ('BloodImage_00' + str(x) + '.jpg' if x > 99 else 'BloodImage_000' + str(x) + '.jpg')\n",
    ")\n",
    "labels_df = labels_df[['Image', 'Category']]\n",
    "#labels_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68fd07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all the test set images\n",
    "\n",
    "all_image_paths = {\n",
    "    os.path.basename(x): x for x in glob(\n",
    "        os.path.join(PATH, '*', '*.jpg')\n",
    "    )\n",
    "}\n",
    "#print('Scans found:', len(all_image_paths), ', Total Headers', labels_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b1b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the image to the right image path\n",
    "labels_df['image_path'] = labels_df['Image'].map(all_image_paths.get)\n",
    "#labels_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b7a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEUTROPHIL    206\n",
      "EOSINOPHIL     88\n",
      "LYMPHOCYTE     33\n",
      "MONOCYTE       20\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dropping categories that have not enough data\n",
    "\n",
    "count_of_labels_per_cat = labels_df.Category.value_counts()\n",
    "to_remove_cat = count_of_labels_per_cat[count_of_labels_per_cat < 10].index \n",
    "df_next = labels_df.replace(to_remove_cat, np.nan)\n",
    "df = df_next.dropna()\n",
    "print(df.Category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "364cc617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data split:  train: (242, 3) test: (105, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "train_df, test_df = train_test_split(\n",
    "    df, \n",
    "    test_size = 0.30,\n",
    "    stratify = df['Category']\n",
    ")\n",
    "print('shape of data split: ', 'train:', f'{train_df.shape}', 'test:', f'{test_df.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a068e238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEUTROPHIL    144\n",
      "EOSINOPHIL     61\n",
      "LYMPHOCYTE     23\n",
      "MONOCYTE       14\n",
      "Name: Category, dtype: int64 \n",
      "\n",
      "NEUTROPHIL    62\n",
      "EOSINOPHIL    27\n",
      "LYMPHOCYTE    10\n",
      "MONOCYTE       6\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show number per category\n",
    "print(train_df.Category.value_counts(), '\\n')\n",
    "print(test_df.Category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf03649",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/lea/Documents/M2/DEA/Tata/CNNBloodCell/dataset-master/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Creating directory and seperate the bulk of images to its own categories\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mCategory\u001b[38;5;241m.\u001b[39munique():\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/lea/Documents/M2/DEA/Tata/CNNBloodCell/dataset-master/train'"
     ]
    }
   ],
   "source": [
    "# Creating directory and seperate the bulk of images to its own categories\n",
    "\n",
    "os.mkdir(f'{PATH}/train')\n",
    "os.mkdir(f'{PATH}/test')\n",
    "\n",
    "for f in df.Category.unique():\n",
    "    os.mkdir(f'{PATH}/train/{f}')\n",
    "    os.mkdir(f'{PATH}/test/{f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7b9f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For TRAIN\n",
    "for p in train_df.itertuples():\n",
    "    file_path = f'{PATH}/JPEGImages/{p.Image}' \n",
    "    train_path = f'{PATH}/train/{p.Category}/{p.Image}'\n",
    "    shutil.copyfile(f'{file_path}', f'{train_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "636f84e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For TEST\n",
    "for p in test_df.itertuples():\n",
    "    file_path = f'{PATH}/JPEGImages/{p.Image}' \n",
    "    test_path = f'{PATH}/test/{p.Category}/{p.Image}'\n",
    "    shutil.copyfile(f'{file_path}', f'{test_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7744d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an test data directory\n",
    "Train = ('/home/lea/Documents/M2/DEA/Tata/CNNBloodCell/dataset-master/train')\n",
    "Test = ('/home/lea/Documents/M2/DEA/Tata/CNNBloodCell/dataset-master/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bdc077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "# https://medium.com/thecyphy/train-cnn-model-with-pytorch-21dafb918f48\n",
    "data_train = ImageFolder(Train,transform = transforms.Compose([\n",
    "    transforms.Resize((120,120)),transforms.ToTensor()\n",
    "]))\n",
    "data_test = ImageFolder(Test,transforms.Compose([\n",
    "    transforms.Resize((120,120)),transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33b2787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follwing classes are there : \n",
      " ['EOSINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\n"
     ]
    }
   ],
   "source": [
    "# Classes\n",
    "print(\"Follwing classes are there : \\n\",data_train.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d82e469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Exploring Images\\ndef display_img(img,label):\\n    print(f\"Label : {data_train.classes[label]}\")\\n    plt.imshow(img.permute(1,2,0))\\n\\n#display the first image in the dataset\\ndisplay_img(*data_train[200])\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Exploring Images\n",
    "def display_img(img,label):\n",
    "    print(f\"Label : {data_train.classes[label]}\")\n",
    "    plt.imshow(img.permute(1,2,0))\n",
    "\n",
    "#display the first image in the dataset\n",
    "display_img(*data_train[200])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c665c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train = DataLoader(data_train, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "test = DataLoader(data_test, batch_size*2, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9d4bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BloodCell(\n",
      "  (network): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): Dropout(p=0.2, inplace=False)\n",
      "    (10): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(8, 4, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Dropout(p=0.2, inplace=False)\n",
      "    (15): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(14, 14))\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=784, out_features=200, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=200, out_features=50, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Linear(in_features=50, out_features=5, bias=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Architecture of our CNN Model:\n",
    "class BloodCell(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # NETWORK\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            # 1\n",
    "            nn.Conv2d(3, 16, kernel_size = 3 , stride = (2,2) , padding = 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.MaxPool2d(kernel_size =3, stride = 2),\n",
    "            \n",
    "            # 2\n",
    "            nn.Conv2d(16, 8, kernel_size = 3 , stride = (2,2) , padding = 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.MaxPool2d(kernel_size =3, stride = 2),\n",
    "            \n",
    "            # 3\n",
    "            nn.Conv2d(8, 4, kernel_size = 3, stride = (2,2), padding = 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.MaxPool2d(kernel_size =3, stride = 2),\n",
    "        )\n",
    "            \n",
    "        # AVGPOOL\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((14,14))\n",
    "        \n",
    "        # CLASSIFIER\n",
    "        self.classifier = nn.Sequential(\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(14*14*4,200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(50,5),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = self.network(xb)\n",
    "        xb = self.avgpool(xb)\n",
    "        xb = self.classifier(xb)\n",
    "        return xb\n",
    "net = BloodCell()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3807781c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0 - Training loss : 1.2013946374257405\n",
      "Epoch1 - Training loss : 1.1431793769200642\n",
      "Epoch2 - Training loss : 1.1321234703063965\n",
      "Epoch3 - Training loss : 1.1611847082773845\n",
      "Epoch4 - Training loss : 1.1073270638783772\n",
      "Epoch5 - Training loss : 1.1346215804417927\n",
      "Epoch6 - Training loss : 1.1199684143066406\n",
      "Epoch7 - Training loss : 1.1295904318491619\n",
      "Epoch8 - Training loss : 1.1497819821039836\n",
      "Epoch9 - Training loss : 1.1196484565734863\n",
      "Epoch10 - Training loss : 1.131909926732381\n",
      "Epoch11 - Training loss : 1.1149966716766357\n",
      "Epoch12 - Training loss : 1.0852822065353394\n",
      "Epoch13 - Training loss : 1.0977526903152466\n",
      "Epoch14 - Training loss : 1.1423275073369343\n",
      "Epoch15 - Training loss : 1.0792396465937297\n",
      "Epoch16 - Training loss : 1.1147671937942505\n",
      "Epoch17 - Training loss : 1.0958145062128704\n",
      "Epoch18 - Training loss : 1.104865829149882\n",
      "Epoch19 - Training loss : 1.1071850061416626\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# LOUIS : A changer et à faire à notre sauce !\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3)\n",
    "batch_size=128\n",
    "\n",
    "for epoch in range (20):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch{} - Training loss : {}\".format(epoch,running_loss/len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e5ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
